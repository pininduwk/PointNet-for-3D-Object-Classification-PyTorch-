{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\n### In this notebook we use [PointNet](https://arxiv.org/abs/1612.00593) to perform 3D Object Classification on [ModelNet10 Dataset](http://modelnet.cs.princeton.edu/#).","metadata":{}},{"cell_type":"markdown","source":"<h3><center>Applications of PointNet</center></h3>\n<img src=\"http://stanford.edu/~rqi/pointnet/images/teaser.jpg\" width=\"600\" height=\"500\"/>\n<h4></h4>\n<h4><center><a href=\"https://arxiv.org/pdf/1612.00593.pdf\">Source: PointNet [Charles R. Qi et. al.]</a></center></h4>","metadata":{}},{"cell_type":"markdown","source":"## Acknowledgements\n\n### This work was inspired by and borrows code from [Nikita Karaev's](https://github.com/nikitakaraevv) [PointNet implementation](https://github.com/nikitakaraevv/pointnet).","metadata":{}},{"cell_type":"markdown","source":"### Libraries ðŸ“šâ¬‡","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport itertools\nimport math, random\nrandom.seed = 42\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\nfrom path import Path\nimport scipy.spatial.distance\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path(\"../input/modelnet10-princeton-3d-object-dataset/ModelNet10\")\n\nfolders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\nclasses = {folder: i for i, folder in enumerate(folders)};\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility Functions","metadata":{}},{"cell_type":"code","source":"def read_off(file):\n    if 'OFF' != file.readline().strip():\n        raise('Not a valid OFF header')\n    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n    return verts, faces\n\n\ndef visualize_rotate(data):\n    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n    frames=[]\n\n    def rotate_z(x, y, z, theta):\n        w = x+1j*y\n        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n\n    for t in np.arange(0, 10.26, 0.1):\n        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n    fig = go.Figure(data=data,\n        layout=go.Layout(\n            updatemenus=[dict(type='buttons',\n                showactive=False,\n                y=1,\n                x=0.8,\n                xanchor='left',\n                yanchor='bottom',\n                pad=dict(t=45, r=10),\n                buttons=[dict(label='Play',\n                    method='animate',\n                    args=[None, dict(frame=dict(duration=50, redraw=True),\n                        transition=dict(duration=0),\n                        fromcurrent=True,\n                        mode='immediate'\n                        )]\n                    )\n                ])]\n        ),\n        frames=frames\n    )\n\n    return fig\n\n\ndef pcshow(xs,ys,zs):\n    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n                                   mode='markers')]\n    fig = visualize_rotate(data)\n    fig.update_traces(marker=dict(size=2,\n                      line=dict(width=2,\n                      color='DarkSlateGrey')),\n                      selector=dict(mode='markers'))\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(path/\"sofa/train/sofa_0002.off\", 'r') as f:\n    verts, faces = read_off(f)\n    \ni,j,k = np.array(faces).T\nx,y,z = np.array(verts).T\nlen(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='yellowgreen', opacity=0.50, i=i,j=j,k=k)]).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_rotate([go.Scatter3d(x=x, y=y, z=z, mode='markers')]).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pcshow(x,y,z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PointSampler(object):\n    def __init__(self, output_size):\n        assert isinstance(output_size, int)\n        self.output_size = output_size\n    \n    def triangle_area(self, pt1, pt2, pt3):\n        side_a = np.linalg.norm(pt1 - pt2)\n        side_b = np.linalg.norm(pt2 - pt3)\n        side_c = np.linalg.norm(pt3 - pt1)\n        s = 0.5 * ( side_a + side_b + side_c)\n        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n\n    def sample_point(self, pt1, pt2, pt3):\n        # barycentric coordinates on a triangle\n        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n        s, t = sorted([random.random(), random.random()])\n        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n        return (f(0), f(1), f(2))\n        \n    \n    def __call__(self, mesh):\n        verts, faces = mesh\n        verts = np.array(verts)\n        areas = np.zeros((len(faces)))\n\n        for i in range(len(areas)):\n            areas[i] = (self.triangle_area(verts[faces[i][0]],\n                                           verts[faces[i][1]],\n                                           verts[faces[i][2]]))\n            \n        sampled_faces = (random.choices(faces, \n                                      weights=areas,\n                                      cum_weights=None,\n                                      k=self.output_size))\n        \n        sampled_points = np.zeros((self.output_size, 3))\n\n        for i in range(len(sampled_faces)):\n            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n                                                   verts[sampled_faces[i][1]],\n                                                   verts[sampled_faces[i][2]]))\n        \n        return sampled_points","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pointcloud = PointSampler(3000)((verts, faces))\npcshow(*pointcloud.T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Normalize(object):\n    def __call__(self, pointcloud):\n        assert len(pointcloud.shape)==2\n        \n        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n\n        return  norm_pointcloud","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_pointcloud = Normalize()(pointcloud)\npcshow(*norm_pointcloud.T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandRotation_z(object):\n    def __call__(self, pointcloud):\n        assert len(pointcloud.shape)==2\n\n        theta = random.random() * 2. * math.pi\n        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n                               [ math.sin(theta),  math.cos(theta),    0],\n                               [0,                             0,      1]])\n        \n        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n        return  rot_pointcloud\n    \nclass RandomNoise(object):\n    def __call__(self, pointcloud):\n        assert len(pointcloud.shape)==2\n\n        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n    \n        noisy_pointcloud = pointcloud + noise\n        return  noisy_pointcloud","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rot_pointcloud = RandRotation_z()(norm_pointcloud)\nnoisy_rot_pointcloud = RandomNoise()(rot_pointcloud)\npcshow(*noisy_rot_pointcloud.T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToTensor(object):\n    def __call__(self, pointcloud):\n        assert len(pointcloud.shape)==2\n\n        return torch.from_numpy(pointcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def default_transforms():\n    return transforms.Compose([\n                                PointSampler(1024),\n                                Normalize(),\n                                ToTensor()\n                              ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Datasets / Dataloaders","metadata":{}},{"cell_type":"code","source":"class PointCloudData(Dataset):\n    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n        self.root_dir = root_dir\n        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n        self.classes = {folder: i for i, folder in enumerate(folders)}\n        self.transforms = transform if not valid else default_transforms()\n        self.valid = valid\n        self.files = []\n        for category in self.classes.keys():\n            new_dir = root_dir/Path(category)/folder\n            for file in os.listdir(new_dir):\n                if file.endswith('.off'):\n                    sample = {}\n                    sample['pcd_path'] = new_dir/file\n                    sample['category'] = category\n                    self.files.append(sample)\n\n    def __len__(self):\n        return len(self.files)\n\n    def __preproc__(self, file):\n        verts, faces = read_off(file)\n        if self.transforms:\n            pointcloud = self.transforms((verts, faces))\n        return pointcloud\n\n    def __getitem__(self, idx):\n        pcd_path = self.files[idx]['pcd_path']\n        category = self.files[idx]['category']\n        with open(pcd_path, 'r') as f:\n            pointcloud = self.__preproc__(f)\n        return {'pointcloud': pointcloud, \n                'category': self.classes[category]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n                    PointSampler(1024),\n                    Normalize(),\n                    RandRotation_z(),\n                    RandomNoise(),\n                    ToTensor()\n                    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = PointCloudData(path, transform=train_transforms)\nvalid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inv_classes = {i: cat for cat, i in train_ds.classes.items()};\ninv_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train dataset size: ', len(train_ds))\nprint('Valid dataset size: ', len(valid_ds))\nprint('Number of classes: ', len(train_ds.classes))\nprint('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\nprint('Class: ', inv_classes[train_ds[0]['category']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(dataset=valid_ds, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3><center>PointNet Model Architecture</center></h3>\n<img src=\"http://stanford.edu/~rqi/pointnet/images/pointnet.jpg\" width=\"750\" height=\"750\"/>\n<h4></h4>\n<h4><center><a href=\"https://arxiv.org/pdf/1612.00593.pdf\">Source: PointNet [Charles R. Qi et. al.]</a></center></h4>","metadata":{}},{"cell_type":"markdown","source":"### Model Definition","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\n\nclass Tnet(nn.Module):\n    def __init__(self, k=3):\n        super().__init__()\n        self.k=k\n        self.conv1 = nn.Conv1d(k,64,1)\n        self.conv2 = nn.Conv1d(64,128,1)\n        self.conv3 = nn.Conv1d(128,1024,1)\n        self.fc1 = nn.Linear(1024,512)\n        self.fc2 = nn.Linear(512,256)\n        self.fc3 = nn.Linear(256,k*k)\n\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.bn5 = nn.BatchNorm1d(256)\n\n\n    def forward(self, input):\n        # input.shape == (bs,n,3)\n        bs = input.size(0)\n        xb = F.relu(self.bn1(self.conv1(input)))\n        xb = F.relu(self.bn2(self.conv2(xb)))\n        xb = F.relu(self.bn3(self.conv3(xb)))\n        pool = nn.MaxPool1d(xb.size(-1))(xb)\n        flat = nn.Flatten(1)(pool)\n        xb = F.relu(self.bn4(self.fc1(flat)))\n        xb = F.relu(self.bn5(self.fc2(xb)))\n\n        #initialize as identity\n        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n        if xb.is_cuda:\n            init=init.cuda()\n        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n        return matrix\n\n\nclass Transform(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.input_transform = Tnet(k=3)\n        self.feature_transform = Tnet(k=64)\n        self.conv1 = nn.Conv1d(3,64,1)\n\n        self.conv2 = nn.Conv1d(64,128,1)\n        self.conv3 = nn.Conv1d(128,1024,1)\n\n\n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n\n    def forward(self, input):\n        matrix3x3 = self.input_transform(input)\n        # batch matrix multiplication\n        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n\n        xb = F.relu(self.bn1(self.conv1(xb)))\n\n        matrix64x64 = self.feature_transform(xb)\n        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n\n        xb = F.relu(self.bn2(self.conv2(xb)))\n        xb = self.bn3(self.conv3(xb))\n        xb = nn.MaxPool1d(xb.size(-1))(xb)\n        output = nn.Flatten(1)(xb)\n        return output, matrix3x3, matrix64x64\n\nclass PointNet(nn.Module):\n    def __init__(self, classes = 10):\n        super().__init__()\n        self.transform = Transform()\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, classes)\n        \n\n        self.bn1 = nn.BatchNorm1d(512)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.dropout = nn.Dropout(p=0.3)\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input):\n        xb, matrix3x3, matrix64x64 = self.transform(input)\n        xb = F.relu(self.bn1(self.fc1(xb)))\n        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n        output = self.fc3(xb)\n        return self.logsoftmax(output), matrix3x3, matrix64x64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n    criterion = torch.nn.NLLLoss()\n    bs=outputs.size(0)\n    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n    if outputs.is_cuda:\n        id3x3=id3x3.cuda()\n        id64x64=id64x64.cuda()\n    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pointnet = PointNet()\npointnet.to(device);\n\n# Load a pre-trained model if it exists\npointnet.load_state_dict(torch.load('../input/pointnet-for-3d-object-classification-pytorch/save.pth'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.00025)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train PointNet","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, val_loader=None,  epochs=4):\n    for epoch in range(epochs): \n        pointnet.train()\n        running_loss = 0.0\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n            optimizer.zero_grad()\n            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n\n            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            if i % 5 == 4:    # print every 10 mini-batches\n                print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n                    (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n                running_loss = 0.0\n\n        pointnet.eval()\n        correct = total = 0\n\n        # validation\n        if val_loader:\n            with torch.no_grad():\n                for data in val_loader:\n                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n                    _, predicted = torch.max(outputs.data, 1)\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n            val_acc = 100. * correct / total\n            print('Valid accuracy: %d %%' % val_acc)\n\n        # save the model\n        torch.save(pointnet.state_dict(), \"save.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(pointnet, train_loader, valid_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test PointNet","metadata":{}},{"cell_type":"code","source":"pointnet.eval()\nall_preds = []\nall_labels = []\nwith torch.no_grad():\n    for i, data in enumerate(valid_loader):\n        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n        \n        inputs, labels = data['pointcloud'].float(), data['category']\n        outputs, __, __ = pointnet(inputs.transpose(1,2))\n        _, preds = torch.max(outputs.data, 1)\n        all_preds += list(preds.numpy())\n        all_labels += list(labels.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(all_labels, all_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplot_confusion_matrix(cm, list(classes.keys()), normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplot_confusion_matrix(cm, list(classes.keys()), normalize=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}